{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uZUNG-cXPwfq"
   },
   "outputs": [],
   "source": [
    "#  Importing all the necessary libraries for EDA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 1.5.3\n",
      "numpy version: 1.24.3\n",
      "re version: 2.2.1\n",
      "seaborn version: 0.12.2\n",
      "matplotlib version: 3.7.1\n",
      "xgboost version: 1.7.6\n",
      "mrmr version: 0.2.8\n",
      "sklearn version: 1.3.1\n",
      "scipy version: 1.10.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import xgboost as xgb\n",
    "import mrmr\n",
    "import sklearn\n",
    "import scipy\n",
    "\n",
    "libraries = {\n",
    "    'pandas': pd,\n",
    "    'numpy': np,\n",
    "    're': re,\n",
    "    'seaborn': sns,\n",
    "    'matplotlib': matplotlib,\n",
    "    'xgboost': xgb,\n",
    "    'mrmr': mrmr,\n",
    "    'sklearn': sklearn,\n",
    "    'scipy': scipy\n",
    "}\n",
    "\n",
    "for lib, module in libraries.items():\n",
    "    try:\n",
    "        print(f'{lib} version: {module.__version__}')\n",
    "    except AttributeError:\n",
    "        print(f'{lib} does not have a __version__ attribute')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h8X4nRzYP7Hh",
    "outputId": "02c6f914-33bf-4c30-d957-b5582fc33849"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\rishi\\anaconda3\\lib\\site-packages (1.7.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\rishi\\anaconda3\\lib\\site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\rishi\\anaconda3\\lib\\site-packages (from xgboost) (1.10.1)\n",
      "Requirement already satisfied: mrmr_selection in c:\\users\\rishi\\anaconda3\\lib\\site-packages (0.2.8)\n",
      "Requirement already satisfied: category-encoders in c:\\users\\rishi\\anaconda3\\lib\\site-packages (from mrmr_selection) (2.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rishi\\anaconda3\\lib\\site-packages (from mrmr_selection) (3.1.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rishi\\anaconda3\\lib\\site-packages (from mrmr_selection) (4.65.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\rishi\\anaconda3\\lib\\site-packages (from mrmr_selection) (1.2.0)\n",
      "Requirement already satisfied: pandas>=1.0.3 in c:\\users\\rishi\\anaconda3\\lib\\site-packages (from mrmr_selection) (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.18.1 in c:\\users\\rishi\\anaconda3\\lib\\site-packages (from mrmr_selection) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\rishi\\anaconda3\\lib\\site-packages (from mrmr_selection) (1.3.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\rishi\\anaconda3\\lib\\site-packages (from mrmr_selection) (1.10.1)\n",
      "Requirement already satisfied: polars>=0.12.5 in c:\\users\\rishi\\anaconda3\\lib\\site-packages (from mrmr_selection) (0.18.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\rishi\\anaconda3\\lib\\site-packages (from pandas>=1.0.3->mrmr_selection) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rishi\\anaconda3\\lib\\site-packages (from pandas>=1.0.3->mrmr_selection) (2022.7)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\rishi\\anaconda3\\lib\\site-packages (from category-encoders->mrmr_selection) (0.14.0)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\rishi\\anaconda3\\lib\\site-packages (from category-encoders->mrmr_selection) (0.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rishi\\anaconda3\\lib\\site-packages (from scikit-learn->mrmr_selection) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rishi\\anaconda3\\lib\\site-packages (from jinja2->mrmr_selection) (2.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\rishi\\anaconda3\\lib\\site-packages (from tqdm->mrmr_selection) (0.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\rishi\\anaconda3\\lib\\site-packages (from patsy>=0.5.1->category-encoders->mrmr_selection) (1.16.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\rishi\\anaconda3\\lib\\site-packages (from statsmodels>=0.9.0->category-encoders->mrmr_selection) (23.0)\n"
     ]
    }
   ],
   "source": [
    "# For mrmr algorithm\n",
    "!pip install xgboost\n",
    "!pip install mrmr_selection\n",
    "from mrmr import mrmr_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "twp99ASJP9Eb"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./CancerCell2022_AZD4547_PRISM.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-272GvtVQX6U"
   },
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "XbX-aXjNQLgU",
    "outputId": "cce3e8e5-651f-47a7-f0e6-e7fa42e3b081"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell line</th>\n",
       "      <th>P37108</th>\n",
       "      <th>Q96JP5</th>\n",
       "      <th>Q9Y4H2</th>\n",
       "      <th>P36578</th>\n",
       "      <th>Q6SPF0</th>\n",
       "      <th>O76031</th>\n",
       "      <th>Q8WUQ7</th>\n",
       "      <th>A6NIH7</th>\n",
       "      <th>Q9BTD8</th>\n",
       "      <th>...</th>\n",
       "      <th>Q5EBL4</th>\n",
       "      <th>P49715</th>\n",
       "      <th>Q5TA45</th>\n",
       "      <th>O14924</th>\n",
       "      <th>Q7Z3B1</th>\n",
       "      <th>O60669</th>\n",
       "      <th>Q13571</th>\n",
       "      <th>Q96JM2</th>\n",
       "      <th>P35558</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACH_000007</td>\n",
       "      <td>70.813376</td>\n",
       "      <td>10.397105</td>\n",
       "      <td>7.838241</td>\n",
       "      <td>245.716342</td>\n",
       "      <td>6.361293</td>\n",
       "      <td>33.219996</td>\n",
       "      <td>0.072112</td>\n",
       "      <td>3.190716</td>\n",
       "      <td>10.932641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016581</td>\n",
       "      <td>0.047859</td>\n",
       "      <td>6.687097</td>\n",
       "      <td>0.196153</td>\n",
       "      <td>0.010548</td>\n",
       "      <td>0.036507</td>\n",
       "      <td>0.015176</td>\n",
       "      <td>0.006032</td>\n",
       "      <td>0.090045</td>\n",
       "      <td>1.750872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACH_000012</td>\n",
       "      <td>45.885932</td>\n",
       "      <td>0.219851</td>\n",
       "      <td>0.038735</td>\n",
       "      <td>95.065502</td>\n",
       "      <td>0.207778</td>\n",
       "      <td>43.659388</td>\n",
       "      <td>0.006217</td>\n",
       "      <td>0.020412</td>\n",
       "      <td>5.581528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007198</td>\n",
       "      <td>0.024734</td>\n",
       "      <td>0.156403</td>\n",
       "      <td>0.019394</td>\n",
       "      <td>0.146396</td>\n",
       "      <td>0.067847</td>\n",
       "      <td>0.011204</td>\n",
       "      <td>3.053069</td>\n",
       "      <td>0.005197</td>\n",
       "      <td>0.935781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACH_000015</td>\n",
       "      <td>97.156593</td>\n",
       "      <td>0.081679</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>223.416202</td>\n",
       "      <td>16.762669</td>\n",
       "      <td>18.645040</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>4.820324</td>\n",
       "      <td>9.788311</td>\n",
       "      <td>...</td>\n",
       "      <td>1.034375</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.084437</td>\n",
       "      <td>0.002895</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.003592</td>\n",
       "      <td>0.047362</td>\n",
       "      <td>0.534410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACH_000018</td>\n",
       "      <td>88.962782</td>\n",
       "      <td>16.162629</td>\n",
       "      <td>0.045823</td>\n",
       "      <td>167.838514</td>\n",
       "      <td>8.445893</td>\n",
       "      <td>18.903743</td>\n",
       "      <td>0.131190</td>\n",
       "      <td>0.194669</td>\n",
       "      <td>12.278054</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930270</td>\n",
       "      <td>0.023918</td>\n",
       "      <td>0.096784</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>6.919319</td>\n",
       "      <td>0.007905</td>\n",
       "      <td>0.007362</td>\n",
       "      <td>0.061330</td>\n",
       "      <td>0.010841</td>\n",
       "      <td>1.034731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACH_000019</td>\n",
       "      <td>66.102366</td>\n",
       "      <td>0.597581</td>\n",
       "      <td>0.015659</td>\n",
       "      <td>109.146344</td>\n",
       "      <td>31.741095</td>\n",
       "      <td>48.016222</td>\n",
       "      <td>0.011203</td>\n",
       "      <td>0.210224</td>\n",
       "      <td>9.051519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043006</td>\n",
       "      <td>0.008505</td>\n",
       "      <td>0.006465</td>\n",
       "      <td>0.131165</td>\n",
       "      <td>0.013341</td>\n",
       "      <td>0.319023</td>\n",
       "      <td>0.021714</td>\n",
       "      <td>0.319655</td>\n",
       "      <td>0.005729</td>\n",
       "      <td>1.125705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6694 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Cell line     P37108     Q96JP5    Q9Y4H2      P36578     Q6SPF0  \\\n",
       "0  ACH_000007  70.813376  10.397105  7.838241  245.716342   6.361293   \n",
       "1  ACH_000012  45.885932   0.219851  0.038735   95.065502   0.207778   \n",
       "2  ACH_000015  97.156593   0.081679  0.000352  223.416202  16.762669   \n",
       "3  ACH_000018  88.962782  16.162629  0.045823  167.838514   8.445893   \n",
       "4  ACH_000019  66.102366   0.597581  0.015659  109.146344  31.741095   \n",
       "\n",
       "      O76031    Q8WUQ7    A6NIH7     Q9BTD8  ...    Q5EBL4    P49715  \\\n",
       "0  33.219996  0.072112  3.190716  10.932641  ...  0.016581  0.047859   \n",
       "1  43.659388  0.006217  0.020412   5.581528  ...  0.007198  0.024734   \n",
       "2  18.645040  0.000067  4.820324   9.788311  ...  1.034375  0.001502   \n",
       "3  18.903743  0.131190  0.194669  12.278054  ...  7.930270  0.023918   \n",
       "4  48.016222  0.011203  0.210224   9.051519  ...  0.043006  0.008505   \n",
       "\n",
       "     Q5TA45    O14924    Q7Z3B1    O60669    Q13571    Q96JM2    P35558  \\\n",
       "0  6.687097  0.196153  0.010548  0.036507  0.015176  0.006032  0.090045   \n",
       "1  0.156403  0.019394  0.146396  0.067847  0.011204  3.053069  0.005197   \n",
       "2  0.084437  0.002895  0.003559  0.000073  0.000333  0.003592  0.047362   \n",
       "3  0.096784  0.000795  6.919319  0.007905  0.007362  0.061330  0.010841   \n",
       "4  0.006465  0.131165  0.013341  0.319023  0.021714  0.319655  0.005729   \n",
       "\n",
       "        AUC  \n",
       "0  1.750872  \n",
       "1  0.935781  \n",
       "2  0.534410  \n",
       "3  1.034731  \n",
       "4  1.125705  \n",
       "\n",
       "[5 rows x 6694 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num = df.rename(columns = {\"Row\" : \"Cell line\"})\n",
    "df_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cjuCPBOBQd8O",
    "outputId": "100119e1-4b21-4cd4-a3e1-9689992f33b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 336 entries, 0 to 335\n",
      "Columns: 6694 entries, Cell line to AUC\n",
      "dtypes: float64(6693), object(1)\n",
      "memory usage: 17.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_num.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336, 6694)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "id": "GRShqBPEQf7W",
    "outputId": "9bcf6377-afc1-4589-f714-b4a5453d7892",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P37108</th>\n",
       "      <th>Q96JP5</th>\n",
       "      <th>Q9Y4H2</th>\n",
       "      <th>P36578</th>\n",
       "      <th>Q6SPF0</th>\n",
       "      <th>O76031</th>\n",
       "      <th>Q8WUQ7</th>\n",
       "      <th>A6NIH7</th>\n",
       "      <th>Q9BTD8</th>\n",
       "      <th>Q9P258</th>\n",
       "      <th>...</th>\n",
       "      <th>Q5EBL4</th>\n",
       "      <th>P49715</th>\n",
       "      <th>Q5TA45</th>\n",
       "      <th>O14924</th>\n",
       "      <th>Q7Z3B1</th>\n",
       "      <th>O60669</th>\n",
       "      <th>Q13571</th>\n",
       "      <th>Q96JM2</th>\n",
       "      <th>P35558</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>316.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>83.632686</td>\n",
       "      <td>8.132749</td>\n",
       "      <td>1.612748</td>\n",
       "      <td>165.098821</td>\n",
       "      <td>7.324946</td>\n",
       "      <td>27.114742</td>\n",
       "      <td>0.189598</td>\n",
       "      <td>1.775281</td>\n",
       "      <td>9.808136</td>\n",
       "      <td>27.973037</td>\n",
       "      <td>...</td>\n",
       "      <td>1.240473</td>\n",
       "      <td>0.144017</td>\n",
       "      <td>2.032112</td>\n",
       "      <td>0.045536</td>\n",
       "      <td>1.913719</td>\n",
       "      <td>0.275918</td>\n",
       "      <td>0.191160</td>\n",
       "      <td>1.100034</td>\n",
       "      <td>0.148420</td>\n",
       "      <td>1.134279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29.891380</td>\n",
       "      <td>7.421937</td>\n",
       "      <td>3.918123</td>\n",
       "      <td>58.046652</td>\n",
       "      <td>6.224560</td>\n",
       "      <td>8.481621</td>\n",
       "      <td>0.620918</td>\n",
       "      <td>3.011331</td>\n",
       "      <td>4.614911</td>\n",
       "      <td>16.813902</td>\n",
       "      <td>...</td>\n",
       "      <td>2.328798</td>\n",
       "      <td>1.186001</td>\n",
       "      <td>2.556285</td>\n",
       "      <td>0.074635</td>\n",
       "      <td>8.548713</td>\n",
       "      <td>0.867393</td>\n",
       "      <td>1.950420</td>\n",
       "      <td>3.015122</td>\n",
       "      <td>1.419955</td>\n",
       "      <td>0.315410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.871144</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>52.138602</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>10.493471</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.040632</td>\n",
       "      <td>0.069447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.338146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>62.239132</td>\n",
       "      <td>0.275456</td>\n",
       "      <td>0.017404</td>\n",
       "      <td>121.851906</td>\n",
       "      <td>0.405916</td>\n",
       "      <td>21.022005</td>\n",
       "      <td>0.006469</td>\n",
       "      <td>0.036925</td>\n",
       "      <td>7.431593</td>\n",
       "      <td>16.389482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016313</td>\n",
       "      <td>0.002123</td>\n",
       "      <td>0.124073</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.014008</td>\n",
       "      <td>0.008036</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>0.012116</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>0.966610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>79.570693</td>\n",
       "      <td>8.710873</td>\n",
       "      <td>0.090736</td>\n",
       "      <td>155.594197</td>\n",
       "      <td>7.207347</td>\n",
       "      <td>26.255362</td>\n",
       "      <td>0.019869</td>\n",
       "      <td>0.145832</td>\n",
       "      <td>9.671402</td>\n",
       "      <td>24.696971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099807</td>\n",
       "      <td>0.010368</td>\n",
       "      <td>0.390519</td>\n",
       "      <td>0.012956</td>\n",
       "      <td>0.060061</td>\n",
       "      <td>0.029092</td>\n",
       "      <td>0.013213</td>\n",
       "      <td>0.053802</td>\n",
       "      <td>0.014366</td>\n",
       "      <td>1.124157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>98.694273</td>\n",
       "      <td>14.224514</td>\n",
       "      <td>0.338013</td>\n",
       "      <td>204.194463</td>\n",
       "      <td>10.821920</td>\n",
       "      <td>31.544788</td>\n",
       "      <td>0.072420</td>\n",
       "      <td>2.940327</td>\n",
       "      <td>12.188851</td>\n",
       "      <td>35.202931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.691962</td>\n",
       "      <td>0.042255</td>\n",
       "      <td>3.963219</td>\n",
       "      <td>0.057607</td>\n",
       "      <td>0.194484</td>\n",
       "      <td>0.100857</td>\n",
       "      <td>0.040940</td>\n",
       "      <td>0.181367</td>\n",
       "      <td>0.046769</td>\n",
       "      <td>1.276990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>200.868844</td>\n",
       "      <td>32.906028</td>\n",
       "      <td>35.842019</td>\n",
       "      <td>349.992452</td>\n",
       "      <td>33.367692</td>\n",
       "      <td>72.999769</td>\n",
       "      <td>5.123537</td>\n",
       "      <td>15.263035</td>\n",
       "      <td>41.350131</td>\n",
       "      <td>125.504910</td>\n",
       "      <td>...</td>\n",
       "      <td>13.098593</td>\n",
       "      <td>15.653247</td>\n",
       "      <td>12.126993</td>\n",
       "      <td>0.477900</td>\n",
       "      <td>98.808962</td>\n",
       "      <td>6.020820</td>\n",
       "      <td>33.304149</td>\n",
       "      <td>14.663321</td>\n",
       "      <td>23.467301</td>\n",
       "      <td>2.692889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 6693 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           P37108      Q96JP5      Q9Y4H2      P36578      Q6SPF0      O76031  \\\n",
       "count  336.000000  336.000000  336.000000  336.000000  336.000000  336.000000   \n",
       "mean    83.632686    8.132749    1.612748  165.098821    7.324946   27.114742   \n",
       "std     29.891380    7.421937    3.918123   58.046652    6.224560    8.481621   \n",
       "min     18.871144    0.000718    0.000098   52.138602    0.000620   10.493471   \n",
       "25%     62.239132    0.275456    0.017404  121.851906    0.405916   21.022005   \n",
       "50%     79.570693    8.710873    0.090736  155.594197    7.207347   26.255362   \n",
       "75%     98.694273   14.224514    0.338013  204.194463   10.821920   31.544788   \n",
       "max    200.868844   32.906028   35.842019  349.992452   33.367692   72.999769   \n",
       "\n",
       "           Q8WUQ7      A6NIH7      Q9BTD8      Q9P258  ...      Q5EBL4  \\\n",
       "count  336.000000  336.000000  336.000000  336.000000  ...  336.000000   \n",
       "mean     0.189598    1.775281    9.808136   27.973037  ...    1.240473   \n",
       "std      0.620918    3.011331    4.614911   16.813902  ...    2.328798   \n",
       "min      0.000013    0.000011    0.040632    0.069447  ...    0.000007   \n",
       "25%      0.006469    0.036925    7.431593   16.389482  ...    0.016313   \n",
       "50%      0.019869    0.145832    9.671402   24.696971  ...    0.099807   \n",
       "75%      0.072420    2.940327   12.188851   35.202931  ...    0.691962   \n",
       "max      5.123537   15.263035   41.350131  125.504910  ...   13.098593   \n",
       "\n",
       "           P49715      Q5TA45      O14924      Q7Z3B1      O60669      Q13571  \\\n",
       "count  336.000000  336.000000  336.000000  336.000000  336.000000  336.000000   \n",
       "mean     0.144017    2.032112    0.045536    1.913719    0.275918    0.191160   \n",
       "std      1.186001    2.556285    0.074635    8.548713    0.867393    1.950420   \n",
       "min      0.000010    0.000180    0.000053    0.000045    0.000073    0.000055   \n",
       "25%      0.002123    0.124073    0.003509    0.014008    0.008036    0.003709   \n",
       "50%      0.010368    0.390519    0.012956    0.060061    0.029092    0.013213   \n",
       "75%      0.042255    3.963219    0.057607    0.194484    0.100857    0.040940   \n",
       "max     15.653247   12.126993    0.477900   98.808962    6.020820   33.304149   \n",
       "\n",
       "           Q96JM2      P35558         AUC  \n",
       "count  336.000000  336.000000  316.000000  \n",
       "mean     1.100034    0.148420    1.134279  \n",
       "std      3.015122    1.419955    0.315410  \n",
       "min      0.000015    0.000013    0.338146  \n",
       "25%      0.012116    0.003662    0.966610  \n",
       "50%      0.053802    0.014366    1.124157  \n",
       "75%      0.181367    0.046769    1.276990  \n",
       "max     14.663321   23.467301    2.692889  \n",
       "\n",
       "[8 rows x 6693 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "vLaSm-Z1QhEk",
    "outputId": "228a929e-5a5a-4253-c78e-14632c78a418"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ACH_000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Cell line\n",
       "count          336\n",
       "unique         336\n",
       "top     ACH_000007\n",
       "freq             1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For categorical variables\n",
    "df_num.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hlyiAFSgmHCx"
   },
   "source": [
    "## 1. Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VCQpg71vQjH8",
    "outputId": "70133c14-1639-4085-f498-55bb2617a26f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AUC']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for columns with NaN values (Missing Values)\n",
    "[features for features in df_num.columns if df_num[features].isna().sum()>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRLgoh-US6Hq"
   },
   "source": [
    "**AUC** is the target columns and has null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8QkFxa4D6B8Z",
    "outputId": "d720c42a-5f85-473c-9c3f-ceb08ed0ba5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the number of missing values in AUC\n",
    "df_num['AUC'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "gVB_3UoETWF1"
   },
   "outputs": [],
   "source": [
    "# Deleting rows with NaN\n",
    "df_num = df_num.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dIuclgU_TAqr",
    "outputId": "b64f2359-8cfd-4c64-bf25-2926925e1f2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cell line    0\n",
       "P37108       0\n",
       "Q96JP5       0\n",
       "Q9Y4H2       0\n",
       "P36578       0\n",
       "            ..\n",
       "O60669       0\n",
       "Q13571       0\n",
       "Q96JM2       0\n",
       "P35558       0\n",
       "AUC          0\n",
       "Length: 6694, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VeKHBf8ZT5LO",
    "outputId": "1873418c-f111-41a4-c60c-792642680a4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for duplicate rows in the dataset\n",
    "df_num.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nwrwbx63T1wZ",
    "outputId": "c73b765f-08bc-49eb-e05a-3721796b1280"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 316 entries, 0 to 335\n",
      "Columns: 6694 entries, Cell line to AUC\n",
      "dtypes: float64(6693), object(1)\n",
      "memory usage: 16.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_num.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "94HElq-MylDo"
   },
   "outputs": [],
   "source": [
    "df_num.drop([\"Cell line\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "c9VLhiLryVBl",
    "outputId": "5c378e20-3e76-4422-9ec0-662c168e60b0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P37108</th>\n",
       "      <th>Q96JP5</th>\n",
       "      <th>Q9Y4H2</th>\n",
       "      <th>P36578</th>\n",
       "      <th>Q6SPF0</th>\n",
       "      <th>O76031</th>\n",
       "      <th>Q8WUQ7</th>\n",
       "      <th>A6NIH7</th>\n",
       "      <th>Q9BTD8</th>\n",
       "      <th>Q9P258</th>\n",
       "      <th>...</th>\n",
       "      <th>Q5EBL4</th>\n",
       "      <th>P49715</th>\n",
       "      <th>Q5TA45</th>\n",
       "      <th>O14924</th>\n",
       "      <th>Q7Z3B1</th>\n",
       "      <th>O60669</th>\n",
       "      <th>Q13571</th>\n",
       "      <th>Q96JM2</th>\n",
       "      <th>P35558</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70.813376</td>\n",
       "      <td>10.397105</td>\n",
       "      <td>7.838241</td>\n",
       "      <td>245.716342</td>\n",
       "      <td>6.361293</td>\n",
       "      <td>33.219996</td>\n",
       "      <td>0.072112</td>\n",
       "      <td>3.190716</td>\n",
       "      <td>10.932641</td>\n",
       "      <td>45.035788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016581</td>\n",
       "      <td>0.047859</td>\n",
       "      <td>6.687097</td>\n",
       "      <td>0.196153</td>\n",
       "      <td>0.010548</td>\n",
       "      <td>0.036507</td>\n",
       "      <td>0.015176</td>\n",
       "      <td>0.006032</td>\n",
       "      <td>0.090045</td>\n",
       "      <td>1.750872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45.885932</td>\n",
       "      <td>0.219851</td>\n",
       "      <td>0.038735</td>\n",
       "      <td>95.065502</td>\n",
       "      <td>0.207778</td>\n",
       "      <td>43.659388</td>\n",
       "      <td>0.006217</td>\n",
       "      <td>0.020412</td>\n",
       "      <td>5.581528</td>\n",
       "      <td>14.606818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007198</td>\n",
       "      <td>0.024734</td>\n",
       "      <td>0.156403</td>\n",
       "      <td>0.019394</td>\n",
       "      <td>0.146396</td>\n",
       "      <td>0.067847</td>\n",
       "      <td>0.011204</td>\n",
       "      <td>3.053069</td>\n",
       "      <td>0.005197</td>\n",
       "      <td>0.935781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97.156593</td>\n",
       "      <td>0.081679</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>223.416202</td>\n",
       "      <td>16.762669</td>\n",
       "      <td>18.645040</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>4.820324</td>\n",
       "      <td>9.788311</td>\n",
       "      <td>79.471739</td>\n",
       "      <td>...</td>\n",
       "      <td>1.034375</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.084437</td>\n",
       "      <td>0.002895</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.003592</td>\n",
       "      <td>0.047362</td>\n",
       "      <td>0.534410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.962782</td>\n",
       "      <td>16.162629</td>\n",
       "      <td>0.045823</td>\n",
       "      <td>167.838514</td>\n",
       "      <td>8.445893</td>\n",
       "      <td>18.903743</td>\n",
       "      <td>0.131190</td>\n",
       "      <td>0.194669</td>\n",
       "      <td>12.278054</td>\n",
       "      <td>31.235398</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930270</td>\n",
       "      <td>0.023918</td>\n",
       "      <td>0.096784</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>6.919319</td>\n",
       "      <td>0.007905</td>\n",
       "      <td>0.007362</td>\n",
       "      <td>0.061330</td>\n",
       "      <td>0.010841</td>\n",
       "      <td>1.034731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.102366</td>\n",
       "      <td>0.597581</td>\n",
       "      <td>0.015659</td>\n",
       "      <td>109.146344</td>\n",
       "      <td>31.741095</td>\n",
       "      <td>48.016222</td>\n",
       "      <td>0.011203</td>\n",
       "      <td>0.210224</td>\n",
       "      <td>9.051519</td>\n",
       "      <td>24.654003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043006</td>\n",
       "      <td>0.008505</td>\n",
       "      <td>0.006465</td>\n",
       "      <td>0.131165</td>\n",
       "      <td>0.013341</td>\n",
       "      <td>0.319023</td>\n",
       "      <td>0.021714</td>\n",
       "      <td>0.319655</td>\n",
       "      <td>0.005729</td>\n",
       "      <td>1.125705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6693 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      P37108     Q96JP5    Q9Y4H2      P36578     Q6SPF0     O76031    Q8WUQ7  \\\n",
       "0  70.813376  10.397105  7.838241  245.716342   6.361293  33.219996  0.072112   \n",
       "1  45.885932   0.219851  0.038735   95.065502   0.207778  43.659388  0.006217   \n",
       "2  97.156593   0.081679  0.000352  223.416202  16.762669  18.645040  0.000067   \n",
       "3  88.962782  16.162629  0.045823  167.838514   8.445893  18.903743  0.131190   \n",
       "4  66.102366   0.597581  0.015659  109.146344  31.741095  48.016222  0.011203   \n",
       "\n",
       "     A6NIH7     Q9BTD8     Q9P258  ...    Q5EBL4    P49715    Q5TA45  \\\n",
       "0  3.190716  10.932641  45.035788  ...  0.016581  0.047859  6.687097   \n",
       "1  0.020412   5.581528  14.606818  ...  0.007198  0.024734  0.156403   \n",
       "2  4.820324   9.788311  79.471739  ...  1.034375  0.001502  0.084437   \n",
       "3  0.194669  12.278054  31.235398  ...  7.930270  0.023918  0.096784   \n",
       "4  0.210224   9.051519  24.654003  ...  0.043006  0.008505  0.006465   \n",
       "\n",
       "     O14924    Q7Z3B1    O60669    Q13571    Q96JM2    P35558       AUC  \n",
       "0  0.196153  0.010548  0.036507  0.015176  0.006032  0.090045  1.750872  \n",
       "1  0.019394  0.146396  0.067847  0.011204  3.053069  0.005197  0.935781  \n",
       "2  0.002895  0.003559  0.000073  0.000333  0.003592  0.047362  0.534410  \n",
       "3  0.000795  6.919319  0.007905  0.007362  0.061330  0.010841  1.034731  \n",
       "4  0.131165  0.013341  0.319023  0.021714  0.319655  0.005729  1.125705  \n",
       "\n",
       "[5 rows x 6693 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cITMhhAOYYQi"
   },
   "source": [
    "## 2. Bootstrapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Atke5UpGYN-H"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_data(dataset):\n",
    "    print(\"Bootstrapping dataset\")\n",
    "    return resample(dataset, replace = True, n_samples = len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. K-Fold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up K Fold to be used later in Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Normalizing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "X7gaJyDfJZsr"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Defining a function to normalize the dataset\n",
    "\n",
    "def norm(data):\n",
    "    \"\"\"\n",
    "    The function takes a pandas dataset as input and returns a normalized pandas dataset (using Standard Scaler) as output\n",
    "    \"\"\"\n",
    "    print(\">Normalizing dataset\")\n",
    "    # Initializing Standard Scaler for normalizing dataset\n",
    "    scaler = StandardScaler()\n",
    "    normalized_data = scaler.fit_transform(data)\n",
    "    \n",
    "    return pd.DataFrame(normalized_data, columns = data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jpwOe7M4Q8lV"
   },
   "source": [
    "## 5. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0dusB3UQ_Af"
   },
   "source": [
    "## Filter methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-iN2O5cRDV_"
   },
   "source": [
    "### 1. Pearson's Correlation (Linear Correlation)\n",
    "\n",
    "Our objective is to find all features with p_value <0.05 and high correlation (negative and positive) with respect to the target value,  **AUC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_pearson(X, y):\n",
    "    \"\"\"\n",
    "    This function takes the dataframe and the target variable as the input arguments and forms a dictionary with the features as keys\n",
    "    and the corresponding correlation and p values as values. It then converts the dictionary into a pandas dataframe and returns only \n",
    "    those features with p_value < 0.05 as function output.\n",
    "    \"\"\"\n",
    "    print(\">Feature selection using Pearson correlation\")\n",
    "    \n",
    "    corr_n_p = {}\n",
    "\n",
    "    for column in X:\n",
    "        # pearsonr returns a tuple (Pearson's correlation coefficient, 2-tailed p-value)\n",
    "        corr, p_value = pearsonr(X[column], y)\n",
    "        corr_n_p[column] = (corr, p_value)\n",
    "\n",
    "    correlation_df = pd.DataFrame.from_dict(corr_n_p, orient='index', columns=['correlation', 'p_value'])\n",
    "    \n",
    "    # Reset the index to move the current index (genes) as a proper column\n",
    "    correlation_df.reset_index(inplace=True)\n",
    "    # Rename the column to 'genes'\n",
    "    correlation_df.rename(columns={'index': 'genes'}, inplace=True)\n",
    "    \n",
    "    # Plotting the graph of correlation vs p-value\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.scatterplot(data=correlation_df, x='correlation', y='p_value', alpha=0.6, edgecolor=None)\n",
    "    plt.axhline(y=0.05, color='r', linestyle='--')\n",
    "    plt.title('Correlation vs P-Value')\n",
    "    plt.xlabel('Correlation')\n",
    "    plt.ylabel('P-Value')\n",
    "    plt.show()\n",
    "    \n",
    "    # Filtering and sorting the significant features\n",
    "    significant_df = correlation_df[correlation_df.p_value < 0.05].sort_values(by='p_value', ascending=True)\n",
    "    \n",
    "    significant_df.reset_index(inplace=True)\n",
    "    significant_df.drop(columns=\"index\", inplace=True)\n",
    "    \n",
    "    # Filtering out the significant features from the actual dataset\n",
    "    features = list(significant_df.genes)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhPY36U8aGli"
   },
   "source": [
    "### 3. MRMR (Maximum Relevance and Minimum Redundancy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to implement mRMR feature selection\n",
    "def mrmr_feature_selection(X,y,k):\n",
    "    # the different column types in the dataset\n",
    "    print(\">Implementing MRMR feature selection\")\n",
    "    return mrmr_regression(X =X, y= y, K = k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l0IsqNUvcbhp"
   },
   "source": [
    "### 4. F-regression (F-statistic and p-values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "aJH1xTB-an62"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_regression, SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to implement F-regression\n",
    "def f_reg_feature_selection(X, y, k):\n",
    "    print(\">Implementing F-regression for feature selection\")\n",
    "    # Using SelectKBest to select the best features\n",
    "    selector = SelectKBest(f_regression, k = k)\n",
    "    new = selector.fit_transform(X,y)\n",
    "    \n",
    "    f_selected = X.columns[selector.get_support()].to_list()\n",
    "    \n",
    "    return f_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "jCTVZIflc7Cc",
    "outputId": "3f568164-0cb0-47ee-bef3-c4d5b0142009"
   },
   "source": [
    "## Embedded Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "uLO-WFRzc7X9"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_cv(X,y):\n",
    "    print(\">Implementing Lasso regularization for feature selection\")\n",
    "    \n",
    "    # Initializing an array of different values for alpha\n",
    "    alphas = np.logspace(-4,4,50)\n",
    "    \n",
    "    # Ensure X and y have matching indices\n",
    "    X = X.reset_index(drop=True)\n",
    "    y = y.reset_index(drop=True)\n",
    "    \n",
    "    # Use LassoCV to find the best alpha using CV\n",
    "    lassocv = LassoCV(alphas = alphas, cv = 5)\n",
    "    lassocv.fit(X,y)\n",
    "    \n",
    "    best_alpha = lassocv.alpha_\n",
    "    print(f\"    best alpha value: {best_alpha}\")\n",
    "    \n",
    "    # Using the best alpha to implemene Lasso Regularization\n",
    "    lasso = Lasso(alpha=best_alpha)\n",
    "\n",
    "    # Fit the Lasso model\n",
    "    lasso.fit(X, y)\n",
    "\n",
    "    # Identify features with non-zero coefficients\n",
    "    lasso_features = np.where(lasso.coef_ != 0)[0]\n",
    "    \n",
    "    return lasso_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting and GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "def xgb_regressor(X,y):\n",
    "    \n",
    "    xgb_results = {}\n",
    "    print('Fitting XGBoost Model')\n",
    "    # Create a XGBoost Regressor object\n",
    "    xgbr = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=0, n_jobs=-1)\n",
    "    \n",
    "    # Param grid for XGBoost\n",
    "    param_grid_xgb = {\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9],\n",
    "    'reg_lambda': [0.2, 0.5, 0.8, 1, 1.2],\n",
    "    'reg_alpha': [0, 0.2, 0.5, 0.8, 1],\n",
    "    'n_estimators': [100, 150, 200, 250, 300],\n",
    "    'min_child_weight': [1, 2, 3, 4],\n",
    "    'max_depth': [5, 6, 7, 8, 9],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 0.4],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9]}\n",
    "\n",
    "\n",
    "    model = xgb.XGBRegressor()\n",
    "\n",
    "    kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "\n",
    "    grid_search = RandomizedSearchCV(model, param_grid_xgb, cv=kf, verbose=1)\n",
    "    \n",
    "    grid_search.fit(X,y)\n",
    "    \n",
    "    print(f\"XGBoost Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"XGBoost Best Score: {grid_search.best_score_}\")\n",
    "    \n",
    "    xgb_results['best_params'] = grid_search.best_params_\n",
    "    xgb_results['best_score'] = grid_search.best_score_\n",
    "    \n",
    "    return xgb_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "\n",
    "def svmachine(X,y):\n",
    "    \n",
    "    svm_results = {}\n",
    "    \n",
    "    print('Fitting Support Vector Machine Model')\n",
    "    \n",
    "    # Param grid for SVM\n",
    "    param_grid_svm = {\n",
    "    'shrinking': [True, False],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid', 'linear'],\n",
    "    'gamma': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5],\n",
    "    'epsilon': [0.0001, 0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "    'degree': [2, 3, 4, 5, 6],\n",
    "    'coef0': [-1, -0.5, 0, 0.5, 1, 1.5],\n",
    "    'C': [0.1, 0.5, 1, 5, 10, 25, 50, 100]}\n",
    "    \n",
    "    model = SVR()\n",
    "\n",
    "    kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "\n",
    "    grid_search = RandomizedSearchCV(model, param_grid_svm, cv=kf, verbose=1, n_jobs=-1)\n",
    "    \n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    print(f\"SVM Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"SVM Best Score: {grid_search.best_score_}\")\n",
    "    \n",
    "    svm_results['best_params'] = grid_search.best_params_\n",
    "    svm_results['best_score'] = grid_search.best_score_\n",
    "    \n",
    "    return svm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP (Neural Network)\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "def mlp_regressor(X,y):\n",
    "    \n",
    "    mlp_results = {}\n",
    "    \n",
    "    # Param Grid for MLP\n",
    "    param_grid_mlp = {\n",
    "    'hidden_layer_sizes': [(50, 50), (100, 100), (50, 50, 50), (150, 150), (100, 100, 100), (50, 50, 50, 50)],\n",
    "    'activation': ['logistic', 'tanh', 'relu', 'identity'],\n",
    "    'solver': ['sgd', 'adam', 'lbfgs'],\n",
    "    'alpha': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1],\n",
    "    'learning_rate': ['constant', 'adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05],\n",
    "    'max_iter': [50, 100, 200, 300, 400, 500],\n",
    "    'momentum': [0.1, 0.5, 0.7, 0.9, 0.95],\n",
    "    'beta_1': [0.7, 0.8, 0.9, 0.95],\n",
    "    'beta_2': [0.99, 0.995, 0.999]}\n",
    "\n",
    "    \n",
    "    print('Fitting Multi-Layer Perceptron Model (Neural Network)')\n",
    "    \n",
    "    kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Initialize MLPRegressor and GridSearchCV\n",
    "    mlp = MLPRegressor(max_iter=1000) # You might want to increase max_iter if the model doesn't converge\n",
    "    grid_search = RandomizedSearchCV(mlp, param_grid_mlp, n_jobs=-1, cv=kf, verbose=1)\n",
    "\n",
    "    # Fit the model\n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    print(f\"MLP Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"MLP Best Score: {grid_search.best_score_}\")\n",
    "    \n",
    "    mlp_results['best_params'] = grid_search.best_params_\n",
    "    mlp_results['best_score'] = grid_search.best_score_\n",
    "    \n",
    "    return mlp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to fit models\n",
    "def model_fitting(X, y):\n",
    "    print(\">Fitting models\")\n",
    "    \n",
    "    results = {}\n",
    "    scores = []\n",
    "    model_names = []\n",
    "    \n",
    "    # Cross validation object\n",
    "    kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "    print('-- Fitting models on default parameters...')\n",
    "    models = {\n",
    "        'SVM': SVR(),\n",
    "        'MLP': MLPRegressor(),\n",
    "        'XGBoost': xgb.XGBRegressor()\n",
    "    }\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        \n",
    "        cv_score_list = cross_val_score(model, X, y, cv = kf)\n",
    "        results[f'{name}'] = (np.mean(cv_score_list)) \n",
    "    \n",
    "    # Selecting the models with the best scores on default values\n",
    "    sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_2_keys = [sorted_results[i][0] for i in range(2)]\n",
    "    \n",
    "    tuning_models = {}\n",
    "    \n",
    "    print(f'--Top 2 models on default parameters:{top_2_keys}')\n",
    "    print('-- Hyperparameter tuning the models')\n",
    "    for mod in  top_2_keys:\n",
    "        if mod == 'SVM':\n",
    "            svm_results = svmachine(X, y)\n",
    "            tuning_models['SVM'] = svm_results\n",
    "        elif mod == 'MLP':\n",
    "            mlp_results = mlp_regressor(X, y)\n",
    "            tuning_models['MLP'] = mlp_results\n",
    "        elif mod == 'XGBoost':\n",
    "            xgb_results = xgb_regressor(X, y)\n",
    "            tuning_models['XGBoost'] = xgb_results\n",
    "    \n",
    "    tuning_results = {}\n",
    "    scores = []\n",
    "    model_names = []\n",
    "    \n",
    "    for name, model in tuning_models.items():\n",
    "        \n",
    "        tuning_results[f'{name}_score'] = (model['best_score'], model['best_params'])\n",
    "        # for plotting\n",
    "        scores.append(model['best_score'])\n",
    "        model_names.append(name)\n",
    "            \n",
    "    # Plotting the scores\n",
    "    plt.figure(figsize=(3, 2))\n",
    "    plt.barh(model_names, scores, color=['blue', 'red', 'green', 'yellow'])\n",
    "    plt.xlabel('Best Score')\n",
    "    plt.title('Model Performance')\n",
    "    plt.gca().invert_yaxis()  # To display the model with the lowest MSE at the top\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"....Model Fitting Done\")\n",
    "    top2 = sorted(tuning_results.items(), key=lambda x: x[1][0], reverse=True)[:2]\n",
    "    print(top2)\n",
    "    return top2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Feature Selection and Backward Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_backward_selection(X, y, top2_models):\n",
    "    \"\"\"\n",
    "    This function performs forward feature selection and backward feature elimination on the dataset\n",
    "    for the top 2 models and returns the selected features for each model and method.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Initializing dictionary to store results\n",
    "    final_features = {}\n",
    "    results = {}\n",
    "    forward_counts = []\n",
    "    backward_counts = []\n",
    "    model_names = []\n",
    "    \n",
    "    \n",
    "    # Extracting the best estimator from the models' results\n",
    "    best_model = top2_models[0][0].split('_')[0]\n",
    "    print(best_model)\n",
    "    \n",
    "    for model_name, (score, params) in top2_models[:1]:\n",
    "        if 'MLP' in model_name.upper():\n",
    "            model = MLPRegressor(**params)\n",
    "        \n",
    "        elif 'SVM' in model_name.upper():\n",
    "            model = SVR(**params)\n",
    "\n",
    "        elif 'XGBOOST' in model_name.upper():\n",
    "            model = xgb.XGBRegressor(**params)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f'Unknown Model name: {model_name}')\n",
    "\n",
    "        # Forward Feature Selection\n",
    "        print(f\">Running Forward Feature Selection for {model_name}\")\n",
    "\n",
    "        # Forward Selection\n",
    "        sfs_forward = SequentialFeatureSelector(model, direction='forward', cv=kf, n_features_to_select=20, n_jobs=-1)\n",
    "        sfs_forward.fit(X, y)\n",
    "        forward_features = X.columns[sfs_forward.get_support()]\n",
    "        print(f'Forward features:{forward_features}')\n",
    "        \n",
    "        print(f\">Running Backward Feature Selection for {model_name}\")\n",
    "        # Backward Selection\n",
    "        sfs_backward = SequentialFeatureSelector(model, direction='backward', cv=kf, n_features_to_select=20, n_jobs=-1)\n",
    "        sfs_backward.fit(X, y)\n",
    "        backward_features = X.columns[sfs_backward.get_support()]\n",
    "        print(f'Backward features:{backward_features}')\n",
    "\n",
    "\n",
    "        # Store results\n",
    "        results[model_name.split('_')[0] + \"_forward\"] = forward_features,\n",
    "        results[model_name.split('_')[0] + \"_backward\"] = backward_features\n",
    "    \n",
    "    print(results)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(dataset, n_bootstraps):\n",
    "    kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "    \n",
    "    # DataFrame to store the results for each bootstrap iteration\n",
    "    results_df = pd.DataFrame(columns=['Bootstrap Iteration Count', 'Best Model',\n",
    "                                       'Best Model Forward Features', 'Best Model Backward Features','Best Model Score'])\n",
    "    \n",
    "    # Iterator for bootstraps\n",
    "    count = 1\n",
    "    \n",
    "    # Create the csv file with headers if it doesn't exist\n",
    "    csv_file = 'bootstrap_final.csv'\n",
    "    \n",
    "    if not os.path.exists(csv_file):\n",
    "        results_df.to_csv(csv_file, index = False)\n",
    "    \n",
    "    for _ in range(n_bootstraps):\n",
    "        print(\"Bootstrapped sample {} of {}\".format(count, n_bootstraps))\n",
    "        \n",
    "        # Bootstrapping\n",
    "        bootstrapped_data = bootstrap_data(dataset)\n",
    "        \n",
    "        # Train and test\n",
    "        X = bootstrapped_data.drop(columns=['AUC'])\n",
    "        y = bootstrapped_data['AUC']\n",
    "        X = X.reset_index(drop=True)\n",
    "        y = y.reset_index(drop=True)\n",
    "        # Normalizing\n",
    "        X_normalized = norm(X)\n",
    "        \n",
    "        # Feature Selection\n",
    "        # Pearson\n",
    "        pearson_features = corr_pearson(X_normalized, y)\n",
    "        \n",
    "        if len(pearson_features)>500:\n",
    "            # MRMR\n",
    "            mrmr_features = mrmr_feature_selection(X_normalized[pearson_features], y, 500)\n",
    "            # F-regression\n",
    "            f_features = f_reg_feature_selection(X_normalized[pearson_features], y, 500)\n",
    "            # Common between mrmr and f-regression\n",
    "            common_features = list(set(mrmr_features) & set(f_features))\n",
    "            print(\"    Number of common features between mrmr and f-regression:{}\".format(len(common_features)))\n",
    "            \n",
    "        else:\n",
    "            common_features = pearson_features\n",
    "        \n",
    "        common_features_df = pd.DataFrame(common_features)\n",
    "        # Write the DataFrame to a CSV file\n",
    "        common_features_df.to_csv('./filter_fs_df.csv', index=False)\n",
    "        # Lasso\n",
    "        embedded_features_indices = lasso_cv(X_normalized[common_features], y)\n",
    "        embedded_features = X_normalized.columns[embedded_features_indices].to_list()\n",
    "        \n",
    "        embedded_df = pd.DataFrame(embedded_features)\n",
    "        # Write the DataFrame to a CSV file\n",
    "        embedded_df.to_csv('./embedded_df.csv', index=False)\n",
    "        \n",
    "        print(\"    Number of common features left after Lasso:{}\".format(len(embedded_features)))\n",
    "        \n",
    "        # Model Selection\n",
    "        top2_models = model_fitting(X_normalized[embedded_features], y)\n",
    "        \n",
    "        \n",
    "        # Extracting model names\n",
    "        best_model_name = top2_models[0][0].split('_')[0]  # Extracting the model name from the result tuple\n",
    "        best_model_r2 = top2_models[0][1][0]\n",
    "        print(f\"    The best model is {best_model_name} with R2 score of {best_model_r2}\")\n",
    "        \n",
    "        if len(embedded_features)>20: # We are trying to filter out the best 20 features\n",
    "            # FFS, BFE\n",
    "            final_features = forward_backward_selection(X_normalized[embedded_features], y, top2_models)\n",
    "\n",
    "            # Extracting forward and backward features for best and second best models\n",
    "            best_model_forward_features = final_features.get(best_model_name + \"_forward\", [])\n",
    "            best_model_backward_features = final_features.get(best_model_name + \"_backward\", [])\n",
    "            \n",
    "        else:\n",
    "            best_model_forward_features = embedded_features\n",
    "            best_model_backward_features = embedded_features\n",
    "        \n",
    "        \n",
    "        # Appending the results to the results dataframe\n",
    "        new_result = {\n",
    "            'Best Model': best_model_name,\n",
    "            'Best Model Forward Features': best_model_forward_features,\n",
    "            'Best Model Backward Features': best_model_backward_features,\n",
    "            'Best Model Score': best_model_r2}\n",
    "        \n",
    "        results_df = results_df.append(new_result, ignore_index=True)\n",
    "        \n",
    "        # Appending to df in the .csv file\n",
    "        pd.DataFrame([new_result]).to_csv(csv_file, mode = 'a', header=False, index=False)\n",
    "        \n",
    "        print(results_df)\n",
    "        print('Data appended to', csv_file)\n",
    "        print(\"----------------------------------------------------------\\n\")\n",
    "        count+=1\n",
    "        \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped sample 1 of 1\n",
      "Bootstrapping dataset\n",
      ">Normalizing dataset\n",
      ">Feature selection using Pearson correlation\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Implementing MRMR feature selection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [03:25<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Implementing F-regression for feature selection\n",
      "    Number of common features between mrmr and f-regression:349\n",
      ">Implementing Lasso regularization for feature selection\n"
     ]
    }
   ],
   "source": [
    "results_df = pipeline(df_num, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
